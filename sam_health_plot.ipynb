{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39adaf3",
   "metadata": {},
   "source": [
    "# Plotting Samsung Health Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb32c8",
   "metadata": {},
   "source": [
    "## Setup and Function Definition\n",
    "\n",
    "The first row always contains a metadata line.\n",
    "The actual header appears in the next row.\n",
    "\n",
    "Each data row may start with an empty leading column (a leading comma),\n",
    "then pandas will assume that first column is the DataFrame index,\n",
    "shifting all columns left so values end up under misaligned headers.\n",
    "\n",
    "Curiously, that happens even if the header has a name for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Matplotlib inline magic command (if not already set)\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "\n",
    "samsung_dump_dir = 'samsunghealth_data'\n",
    "samsung_csv_paths = glob(os.path.join(samsung_dump_dir, '*.csv'))\n",
    "\n",
    "# Define the namedtuple structure for time-series statistics\n",
    "TimeSeriesResult = namedtuple('TimeSeriesResult', 'mean max min')\n",
    "\n",
    "def check_jupyter_environment():\n",
    "    \"\"\"\n",
    "    Checks if the code is running within an IPython/Jupyter environment.\n",
    "\n",
    "    Detecting the environment is often necessary to control output and behavior:\n",
    "    - Display Formatting: Choosing between print() (standard terminal)\n",
    "      and display() (rich HTML tables/Markdown in Jupyter).\n",
    "    - Progress Bars: Using tqdm.notebook (for Jupyter) instead of tqdm (for terminal).\n",
    "    - Enabling or disabling interactive widgets that only work in notebook environments.\n",
    "    - File Paths: Handling relative file paths differently\n",
    "      if the script is run from a terminal versus within a notebook cell.\n",
    "    \"\"\"\n",
    "    # The function get_ipython() is defined when running in any IPython shell,\n",
    "    # including Jupyter Notebooks and JupyterLab.\n",
    "    try:\n",
    "        # Check if the global function get_ipython() exists\n",
    "        shell = get_ipython().__class__.__name__  # type: ignore to hush Pylance/Pyright\n",
    "        \n",
    "        # 'ZMQInteractiveShell' is used by Jupyter Notebook/Lab\n",
    "        # 'TerminalInteractiveShell' is used by standard IPython console\n",
    "        if 'TerminalInteractiveShell' in shell or 'ZMQInteractiveShell' in shell:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    except NameError:\n",
    "        # get_ipython is not defined, so it's likely a standard Python interpreter\n",
    "        return False\n",
    "\n",
    "is_running_in_jupyter = check_jupyter_environment()\n",
    "\n",
    "\n",
    "if is_running_in_jupyter:\n",
    "    from IPython.display import display, Markdown, HTML\n",
    "\n",
    "\n",
    "# Define an anonymous function that reads CSV files\n",
    "# using the pandas library with these specific arguments:\n",
    "#   `skiprows=1`: ignore the first metadata line.\n",
    "#   `index_col=False`: ensure the first column is treated as a regular data column.\n",
    "sam_readcsv = lambda x: pd.read_csv(x, skiprows=1, index_col=False)\n",
    "\n",
    "\n",
    "def get_samsung_csv_path(sample_base_name):\n",
    "    \"\"\"\n",
    "    Retrieves the full path of a Samsung Health log file based on its base name.\n",
    "\n",
    "    Searches the list of all CSV paths (`samsung_csv_paths`) for a file\n",
    "    whose basename contains the given `sample_base_name`. This is useful\n",
    "    for matching a log type (e.g., 'heart_rate') regardless of its \n",
    "    extracted datetime stamp suffix.\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the first matching file, or empty if not found.\n",
    "    \"\"\"\n",
    "    for samples_full_path in samsung_csv_paths:\n",
    "        if sample_base_name in os.path.basename(samples_full_path):\n",
    "            return samples_full_path\n",
    "    return ''  # not found\n",
    "\n",
    "\n",
    "def csv_to_time_series_df(csv_file_path, timestamp_col_name):\n",
    "    \"\"\"\n",
    "        Loads a CSV file into a time-series pandas DataFrame.\n",
    "\n",
    "        The function first loads the data using the custom 'sam_readcsv' loader, \n",
    "        ensures the specified timestamp column is converted to the proper datetime type,\n",
    "        and then sets this column as the DataFrame index for time-series analysis.\n",
    "\n",
    "        Args:\n",
    "            csv_file_path (str): The full path to the CSV file to be loaded.\n",
    "            timestamp_col_name (str): The exact name of the column containing the \n",
    "                timestamp values.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A DataFrame indexed by the converted datetime column, \n",
    "                ready for time-series plotting or manipulation.\n",
    "    \"\"\"\n",
    "    # Loads the specified CSV file into a pandas Data Frame\n",
    "    df = sam_readcsv(csv_file_path)\n",
    "\n",
    "    # Convert the timestamp column to datetime objects\n",
    "    df[timestamp_col_name] = pd.to_datetime(df[timestamp_col_name])\n",
    "\n",
    "    # Set the timestamp column as the DataFrame index and return\n",
    "    return df.set_index(timestamp_col_name)\n",
    "\n",
    "\n",
    "def get_time_series_stat(time_series_df, column_name, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Compute statistics analyzing the column_name in a time interval,\n",
    "    assuming time-series DataFrame has a DatetimeIndex.\n",
    "\n",
    "    Returns:\n",
    "        TimeSeriesResult\n",
    "    \"\"\"\n",
    "    # Selects all rows where the index (timestamp) falls between the two times\n",
    "    # using boolean indexing to filter rows\n",
    "    interval_data = time_series_df[\n",
    "        (time_series_df.index >= start_time) & \n",
    "        (time_series_df.index <= end_time)\n",
    "    ]\n",
    "\n",
    "    # Select the specific column data within that interval\n",
    "    interval_series = interval_data[column_name]\n",
    "\n",
    "    # Compute and return the statistics\n",
    "    return TimeSeriesResult(mean=interval_series.mean(), max=interval_series.max(), min=interval_series.min())\n",
    "\n",
    "\n",
    "def display_stat(time_series_df, column_name, start_time, end_time):\n",
    "    # Ensure the times are converted to the correct pandas Timestamp objects\n",
    "    start_timestamp = pd.to_datetime(start_time)\n",
    "    end_timestamp = pd.to_datetime(end_time)\n",
    "\n",
    "    # Format date to European (DD/MM/YYYY)\n",
    "    start_date = start_timestamp.strftime(\"%d/%m/%Y\")\n",
    "    end_date = end_timestamp.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    display(Markdown(f'--- Statistics for **{column_name.split(\".\")[-1].strip()}** from {start_date} to {end_date} ---'))\n",
    "    statistics = get_time_series_stat(time_series_df, column_name, start_timestamp, end_timestamp)\n",
    "\n",
    "    # Printing Statistics as a Formatted Table\n",
    "    # Separator length is according to f-strings spacing and decimal precision\n",
    "    table_line_separator = \"-\" * (5 + 3 + 5 + 3 + 6)\n",
    "    # Print the table header\n",
    "    print(f'{\"Min\":<5} | {\"Max\":<5} | {\"Mean\":<6}')\n",
    "    print(table_line_separator)\n",
    "    # Print the row\n",
    "    print(f'{statistics.min:<5.0f} | {statistics.max:<5.0f} | {statistics.mean:<6.0f}')\n",
    "    print(table_line_separator)\n",
    "\n",
    "\n",
    "def display_statistics(data_frame):\n",
    "    \"\"\"\n",
    "    Displays a DataFrame as a nicely formatted.\n",
    "    Uses rich rendering in Jupyter and clean text rendering in console.\n",
    "\n",
    "    Args:\n",
    "        data_frame (pd.DataFrame): The DataFrame to be displayed.\n",
    "    \"\"\"\n",
    "    if is_running_in_jupyter:\n",
    "        # --- JUPYTER/IPYTHON OUTPUT (Rich HTML tables/Markdown) ---\n",
    "\n",
    "        # Display also the row number (the DataFrame index)\n",
    "        #display(statistics_df)\n",
    "        # or\n",
    "        # Omit the row number (the DataFrame index) when displaying:\n",
    "        #   1. Use the index=False converting the DataFrame to HTML\n",
    "        #   2. Display the resulting HTML in the notebook\n",
    "        html_output = data_frame.to_html(index=False)\n",
    "        display(HTML(html_output))\n",
    "\n",
    "    else:\n",
    "        # --- STANDARD CONSOLE OUTPUT (Plain Text) ---\n",
    "\n",
    "        # Use tabulate for clean, formatted ASCII table printing\n",
    "        # headers='keys' uses the column names as the header\n",
    "        # tablefmt='grid' creates a neat, boxed table\n",
    "        table_output = tabulate(\n",
    "            data_frame, \n",
    "            headers='keys', \n",
    "            tablefmt='grid',\n",
    "            showindex=False # Explicitly tells tabulate to omit the pandas index\n",
    "        )\n",
    "        \n",
    "        print(table_output)\n",
    "        # print(\"-\" * (len(table_output.split('\\n')[0]))) # Print separator based on table width\n",
    "    \n",
    "\n",
    "def display_stat_table(time_series_df, column_name, period_list):\n",
    "    statistics_df = pd.DataFrame(columns=['Observation Period', 'Minimum', 'Maximum', 'Average'])\n",
    "    for period in period_list:\n",
    "        # Ensure the times are converted to the correct pandas Timestamp objects\n",
    "        start_timestamp = pd.to_datetime(period[0])\n",
    "        end_timestamp = pd.to_datetime(period[1])\n",
    "\n",
    "        statistics = get_time_series_stat(time_series_df, column_name, start_timestamp, end_timestamp)\n",
    "\n",
    "        # Format date to European (DD/MM/YYYY)\n",
    "        start_date = start_timestamp.strftime(\"%d/%m/%Y\")\n",
    "        end_date = end_timestamp.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "        # Append results\n",
    "        period_str = f'{start_date} - {end_date}'\n",
    "        statistics_df.loc[len(statistics_df)] = [period_str, round(statistics.min), round(statistics.max), round(statistics.mean)]\n",
    "    \n",
    "    display_statistics(statistics_df)\n",
    "    \n",
    "\n",
    "def samsung_plot(time_series_df, size_tuple, banner, y_axis_name, column_names_list):\n",
    "    \"\"\"\n",
    "    Generate a time-series plot using the timestamp for the x-axis\n",
    "    and plotting the remaining selected data columns on the y-axis of the same axes set.\n",
    "    \"\"\"\n",
    "    # Select columns for plotting\n",
    "    plot_data = time_series_df[column_names_list].copy()\n",
    "\n",
    "    # Create the figure and axes\n",
    "    plt.figure(figsize=size_tuple)\n",
    "\n",
    "    # Plot columns. Pandas uses the column names as the legend labels.\n",
    "    ax = plot_data.plot(\n",
    "        title=banner,\n",
    "        grid=True,\n",
    "        figsize=size_tuple  # Re-specifying size just in case\n",
    "    )\n",
    "\n",
    "    # Rename the legend labels for clarity\n",
    "    labels = []\n",
    "    # If a column name consists of dot-separated components, only the last is checked.\n",
    "    for column_name in column_names_list:\n",
    "        labels.append(column_name.split(\".\")[-1].strip())\n",
    "    ax.legend(labels)\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(y_axis_name)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f6aa1",
   "metadata": {},
   "source": [
    "## Pandas `strftime` issue using Pylance/Pyright\n",
    "\n",
    "Pylance is the default language server for Python in VS Code (powered by Microsoft's Pyright type checker).\n",
    "\n",
    "In the following code snippets, you can find patterns like this:\n",
    "```Python\n",
    "# Convert the time column to datetime objects\n",
    "df[time_column_name] = pd.to_datetime(df[time_column_name])\n",
    "\n",
    "# Set the datetime column as the DataFrame index\n",
    "df = df.set_index(time_column_name)\n",
    "\n",
    "# Format Datetime to European (DD/MM/YYYY HH.MM.SS)\n",
    "df[time_column_name] = df.index.strftime('%d/%m/%Y %H.%M.%S')\n",
    "```\n",
    "In the above last statement, Pyright highlights `strftime` as unknown attribute even if the code executes successfully.\n",
    "\n",
    "### Why Pylance/Pyright Think It's Unknown (Static Analysis)\n",
    "Pylance/Pyright perform static code analysis. This means they analyze your code without running it. They read the code and try to figure out the type of every variable based on the imports and function calls.\n",
    "\n",
    "1. `df.index`: The `.index` attribute of a pandas DataFrame typically returns a generic index type, such as a `RangeIndex` or an `Int64Index`.\n",
    "\n",
    "2. Pyright sees the `.index` and correctly identifies its type. Generic Index objects do not have a `.strftime()` method.\n",
    "\n",
    "3. Because Pyright doesn't know the exact runtime data (it only sees the static code), it flags an `unknown attribute` error, assuming the `strftime` method doesn't exist on the generic index type.\n",
    "\n",
    "### Why It Executes Successfully (Runtime Execution)\n",
    "The code works because of pandas' specialized functionality for Datetime Indexes:\n",
    "\n",
    "1. **Index Type**: The `df.index` object is not a generic index; it is a `DatetimeIndex` (because you successfully used `set_index(time_column_name)` with a converted datetime column earlier in your script).\n",
    "\n",
    "2. **`DatetimeIndex` Method**: Unlike generic indexes, the `DatetimeIndex` object does have a native `.strftime()` method specifically designed to format its datetime elements.\n",
    "\n",
    "3. **Jupyter Execution**: When you run the cell in Jupyter, Python executes the code, recognizes the `df.index` as a `DatetimeIndex`, finds the correct `.strftime()` method, and executes it without error.\n",
    "\n",
    "### How to Silence Pylance/Pyright\n",
    "A. Use Pyright Comment to Ignore the Line Completely\n",
    "\n",
    "Add this comment to the end of the problematic line:\n",
    "```Python\n",
    "df[time_column_name] = df.index.strftime('%d/%m/%Y %H.%M.%S') # type: ignore\n",
    "```\n",
    "\n",
    "B. Ignore Specific Error Code\n",
    "\n",
    "If you find the specific error code Pylance is raising (e.g., in the VS Code \"Problems\" panel), you can target it:\n",
    "```Python\n",
    "# Assuming the error is 'reportAttributeAccessIssue'\n",
    "df[time_column_name] = df.index.strftime('%d/%m/%Y %H.%M.%S') # type: ignore [reportAttributeAccessIssue]\n",
    "```\n",
    "\n",
    "**NOTE**: If you use Pylint as static analyzers, the special comment to add is the following:\n",
    "```Python\n",
    "df[time_column_name] = df.index.strftime('%d/%m/%Y %H.%M.%S')  # pylint: disable=no-member\n",
    "```\n",
    "\n",
    "C. Pythonic Resolution\n",
    "\n",
    "While the current code is correct for a `DatetimeIndex`, the more general pandas way to access datetime properties is through the `.dt.strftime()` method,\n",
    "which is used on a Series of datetime objects. While this requires the index to be converted back to a Series or column,\n",
    "it is a very common pattern that is less likely to confuse static analyzers\n",
    "(**though not strictly necessary here** since you were on a `DatetimeIndex`):\n",
    "```Python\n",
    "# Convert index back to a Series to use the standard .dt accessor\n",
    "df[time_column_name] = df.index.to_series().dt.strftime('%d/%m/%Y %H.%M.%S')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8993f27",
   "metadata": {},
   "source": [
    "## Heart rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138692d",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87319f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_csv = get_samsung_csv_path('com.samsung.shealth.tracker.heart_rate.')\n",
    "\n",
    "# Select the relevant columns\n",
    "hr_column_name = 'com.samsung.health.heart_rate.heart_rate'\n",
    "time_column_name = 'com.samsung.health.heart_rate.end_time'\n",
    "\n",
    "heart_rate_df = csv_to_time_series_df(heart_rate_csv, time_column_name)\n",
    "start_period_timestamp = heart_rate_df.index.min()\n",
    "end_period_timestamp = heart_rate_df.index.max()\n",
    "plot_title = f'Heart Rate (BPM) Statistics from {start_period_timestamp.strftime(\"%d/%m/%Y\")} to {end_period_timestamp.strftime(\"%d/%m/%Y\")}'\n",
    "\n",
    "display(Markdown(f\"### {plot_title}\"))\n",
    "\n",
    "# Show statistics from the whole time interval\n",
    "# display_stat(heart_rate_df, hr_column_name, start_period_timestamp, end_period_timestamp)\n",
    "\n",
    "# Show statistics from partial time interval\n",
    "# display_stat(heart_rate_df, hr_column_name, start_period_timestamp, '2025-10-11')\n",
    "# display_stat(heart_rate_df, hr_column_name, '2025-10-12', end_period_timestamp)\n",
    "display_stat_table(heart_rate_df, hr_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp)\n",
    "])\n",
    "display_stat_table(heart_rate_df, hr_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp),\n",
    "])\n",
    "\n",
    "# Plot\n",
    "display(Markdown(f\"### Plotting Data Source: **{os.path.basename(heart_rate_csv)}**\"))\n",
    "samsung_plot(heart_rate_df,\n",
    "             (11, 6),\n",
    "             plot_title,\n",
    "             'Heart Rate (BPM)',\n",
    "             [hr_column_name]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dece56",
   "metadata": {},
   "source": [
    "### Data export with European formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ded42",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'heart_rate_european_format.csv'\n",
    "\n",
    "# Use the prepared blood pressure DataFrame\n",
    "hr_export_df = heart_rate_df.copy()\n",
    "\n",
    "# Format Datetime to European (DD/MM/YYYY HH.MM.SS)\n",
    "time_format_col = 'Timestamp (European Format)'\n",
    "hr_export_df[time_format_col] = hr_export_df.index.strftime('%d/%m/%Y %H.%M.%S')  # type: ignore [reportAttributeAccessIssue]\n",
    "\n",
    "# Reset index to make the BP columns accessible as data columns\n",
    "hr_export_df = hr_export_df.reset_index(drop=True)\n",
    "\n",
    "# Convert numerics to string and replace decimal point\n",
    "new_hr_col = 'Heart Rate (bpm)'\n",
    "hr_export_df[new_hr_col] = hr_export_df[hr_column_name].astype(str).str.replace('.', ',', regex=False)\n",
    "\n",
    "# Select and reorder the final columns\n",
    "final_cols = [time_format_col, new_hr_col]\n",
    "br_final_df = hr_export_df[final_cols]\n",
    "\n",
    "# Use a semicolon (;) as the delimiter for European format compatibility\n",
    "br_final_df.to_csv(output_file_name, index=False, sep=';')\n",
    "\n",
    "print(f\"Successfully exported data to: {output_file_name}\")\n",
    "print(\"First few rows of the exported CSV (note the comma decimals):\")\n",
    "display(br_final_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f301d",
   "metadata": {},
   "source": [
    "## Heart rate during exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a258017",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cb454",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_csv = get_samsung_csv_path('com.samsung.shealth.exercise.')\n",
    "\n",
    "# Select the relevant columns\n",
    "mean_column_name = 'com.samsung.health.exercise.mean_heart_rate'\n",
    "max_column_name = 'com.samsung.health.exercise.max_heart_rate'\n",
    "min_column_name = 'com.samsung.health.exercise.min_heart_rate'\n",
    "time_column_name = 'com.samsung.health.exercise.end_time'\n",
    "\n",
    "heart_rate_df = csv_to_time_series_df(heart_rate_csv, time_column_name)\n",
    "start_period_timestamp = heart_rate_df.index.min()\n",
    "end_period_timestamp = heart_rate_df.index.max()\n",
    "plot_title = f'Heart Rate (BPM) Statistics During Exercise from {start_period_timestamp.strftime(\"%d/%m/%Y\")} to {end_period_timestamp.strftime(\"%d/%m/%Y\")}'\n",
    "\n",
    "display(Markdown(f\"### {plot_title}\"))\n",
    "\n",
    "# Show statistics from the whole time interval\n",
    "# display_stat(heart_rate_df, min_column_name, start_period_timestamp, end_period_timestamp)\n",
    "# display_stat(heart_rate_df, max_column_name, start_period_timestamp, end_period_timestamp)\n",
    "\n",
    "# Show statistics from partial time interval\n",
    "# display_stat(heart_rate_df, min_column_name, start_period_timestamp, '2025-10-11')\n",
    "# display_stat(heart_rate_df, max_column_name, start_period_timestamp, '2025-10-11')\n",
    "\n",
    "# display_stat(heart_rate_df, min_column_name, '2025-10-12', end_period_timestamp)\n",
    "# display_stat(heart_rate_df, max_column_name, '2025-10-12', end_period_timestamp)\n",
    "\n",
    "display(Markdown(f'--- **Minimum** Hear Rate Summary Table ---'))\n",
    "display_stat_table(heart_rate_df, min_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp)\n",
    "])\n",
    "\n",
    "display(Markdown(f'--- **Maximum** Hear Rate Summary Table ---'))\n",
    "display_stat_table(heart_rate_df, max_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp)\n",
    "])\n",
    "\n",
    "display(Markdown(f\"### Plotting Data Source: **{os.path.basename(heart_rate_csv)}**\"))\n",
    "samsung_plot(heart_rate_df,\n",
    "             (11, 7),\n",
    "             plot_title,\n",
    "             'Heart Rate (BPM)',\n",
    "             [min_column_name, max_column_name]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0bc96",
   "metadata": {},
   "source": [
    "## Systolic (SYS) and diastolic (DIA) blood pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d861522",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd914e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_pressure_csv = get_samsung_csv_path('com.samsung.shealth.blood_pressure.')\n",
    "\n",
    "# Select the relevant columns\n",
    "sys_column_name = 'com.samsung.health.blood_pressure.systolic'\n",
    "dia_column_name = 'com.samsung.health.blood_pressure.diastolic'\n",
    "pulse_column_name = 'com.samsung.health.blood_pressure.pulse'\n",
    "time_column_name = 'com.samsung.health.blood_pressure.update_time'\n",
    "\n",
    "blood_pressure_df = csv_to_time_series_df(blood_pressure_csv, time_column_name)\n",
    "start_period_timestamp = blood_pressure_df.index.min()\n",
    "end_period_timestamp = blood_pressure_df.index.max()\n",
    "plot_title = f'Blood Pressure Over Time (Systolic and Diastolic) {start_period_timestamp.strftime(\"%d/%m/%Y\")} to {end_period_timestamp.strftime(\"%d/%m/%Y\")}'\n",
    "\n",
    "display(Markdown(f\"### {plot_title}\"))\n",
    "\n",
    "# Show statistics from the whole time interval\n",
    "# display_stat(blood_pressure_df, sys_column_name, start_period_timestamp, end_period_timestamp)\n",
    "# display_stat(blood_pressure_df, dia_column_name, start_period_timestamp, end_period_timestamp)\n",
    "# display_stat(blood_pressure_df, pulse_column_name, start_period_timestamp, end_period_timestamp)\n",
    "\n",
    "# Show statistics from partial time interval\n",
    "# display_stat(blood_pressure_df, sys_column_name, start_period_timestamp, '2025-10-11')\n",
    "# display_stat(blood_pressure_df, dia_column_name, start_period_timestamp, '2025-10-11')\n",
    "# display_stat(blood_pressure_df, pulse_column_name, start_period_timestamp, '2025-10-11')\n",
    "\n",
    "# display_stat(blood_pressure_df, sys_column_name, '2025-10-12', end_period_timestamp)\n",
    "# display_stat(blood_pressure_df, dia_column_name, '2025-10-12', end_period_timestamp)\n",
    "# display_stat(blood_pressure_df, pulse_column_name, '2025-10-12', end_period_timestamp)\n",
    "\n",
    "display(Markdown(f'--- **Systolic (mmHg)** Summary Table ---'))\n",
    "display_stat_table(blood_pressure_df, sys_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp)\n",
    "])\n",
    "\n",
    "display(Markdown(f'--- **Diastolic (mmHg)** Summary Table ---'))\n",
    "display_stat_table(blood_pressure_df, dia_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp)\n",
    "])\n",
    "\n",
    "display(Markdown(f'--- **Heart Rate (BPM)** Summary Table ---'))\n",
    "display_stat_table(blood_pressure_df, pulse_column_name, [\n",
    "    (start_period_timestamp, '2025-10-11'),\n",
    "    ('2025-10-12', end_period_timestamp)\n",
    "])\n",
    "\n",
    "display(Markdown(f\"### Plotting Data Source: **{os.path.basename(blood_pressure_csv)}**\"))\n",
    "samsung_plot(blood_pressure_df,\n",
    "             (11, 7),\n",
    "             plot_title,\n",
    "             'Blood Pressure (mmHg)',\n",
    "             [sys_column_name, dia_column_name, pulse_column_name]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98011cac",
   "metadata": {},
   "source": [
    "### Data export with European formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'blood_pressure_european_format.csv'\n",
    "    \n",
    "# Use the prepared blood pressure DataFrame\n",
    "bp_export_df = blood_pressure_df.copy()\n",
    "\n",
    "# Format Datetime to European (DD/MM/YYYY HH.MM.SS)\n",
    "time_format_col = 'Timestamp (European Format)'\n",
    "bp_export_df[time_format_col] = bp_export_df.index.strftime('%d/%m/%Y %H.%M.%S')  # type: ignore [reportAttributeAccessIssue]\n",
    "\n",
    "# Reset index to make the BP columns accessible as data columns\n",
    "bp_export_df = bp_export_df.reset_index(drop=True)\n",
    "\n",
    "# Convert numerics to string and replace decimal point\n",
    "new_sys_col = 'Systolic (mmHg)'\n",
    "new_dia_col = 'Diastolic (mmHg)'\n",
    "new_pulse_col = 'Heart Rate (bpm)'\n",
    "bp_export_df[new_sys_col] = bp_export_df[sys_column_name].astype(str).str.replace('.', ',', regex=False)\n",
    "bp_export_df[new_dia_col] = bp_export_df[dia_column_name].astype(str).str.replace('.', ',', regex=False)\n",
    "bp_export_df[new_pulse_col] = bp_export_df[pulse_column_name].astype(str).str.replace('.', ',', regex=False)\n",
    "\n",
    "# Select and reorder the final columns\n",
    "final_cols = [time_format_col, new_sys_col, new_dia_col, new_pulse_col]\n",
    "bp_final_df = bp_export_df[final_cols]\n",
    "\n",
    "# Use a semicolon (;) as the delimiter for European format compatibility\n",
    "bp_final_df.to_csv(output_file_name, index=False, sep=';')\n",
    "\n",
    "print(f\"Successfully exported data to: {output_file_name}\")\n",
    "print(\"First few rows of the exported CSV (note the comma decimals):\")\n",
    "display(bp_final_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
